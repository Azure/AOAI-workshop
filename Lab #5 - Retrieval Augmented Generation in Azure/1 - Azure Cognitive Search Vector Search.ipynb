{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Cognitive Search Vector Search Code Sample with Azure OpenAI\n",
    "This code demonstrates how to use Azure Cognitive Search with OpenAI and Azure Python SDK\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import Vector\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    PrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchField,\n",
    "    SemanticSettings,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment variables\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "  api_key=OPENAI_API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n",
    "credential = AzureKeyCredential(key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings\n",
    "Read your data, generate OpenAI embeddings and export to a format to insert your Azure Cognitive Search index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:101: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:108: UserWarning: As of openai>=1.0.0, if `deployment` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dschlesinger\\code\\ongoing\\workshops\\AOAI-workshop\\.venv\\lib\\site-packages\\langchain\\embeddings\\azure_openai.py:116: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://aidemos-workshop.openai.azure.com/ to https://aidemos-workshop.openai.azure.com//openai.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.009420825504358491, -0.004646901672600355, -0.0015674912696747403]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test embedding with langchain\n",
    "embeddingmodel = AzureOpenAIEmbeddings(\n",
    "    deployment=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    model=OPENAI_ADA_EMBEDDING_MODEL_NAME,\n",
    "    openai_api_base=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    chunk_size = 1)\n",
    "\n",
    "vec = embeddingmodel.embed_query(\"transform to vec\")\n",
    "vec[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    embeddings = embeddingmodel.embed_query(text)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for loading into Azure Cognitive Search - DO THIS ONLY ONCE !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  187\n"
     ]
    }
   ],
   "source": [
    "doc_title = \"Semantic Kernel\"\n",
    "# load pdf and split into pages\n",
    "fileName = \"./data/semantic-kernel.pdf\"\n",
    "loader = PyPDFLoader(fileName)\n",
    "pages = loader.load_and_split()\n",
    "print(\"Number of pages: \", len(pages))\n",
    "\n",
    "doc_with_vector_list = []\n",
    "doc_id = 0\n",
    "# Generate embeddings for title and content fields\n",
    "for page in pages:\n",
    "    page_with_vector = {}\n",
    "    page_with_vector['id'] = str(doc_id)\n",
    "    page_with_vector['title'] = doc_title\n",
    "    page_with_vector['titleVector'] = generate_embeddings(doc_title)\n",
    "    page_with_vector['content'] = page.page_content\n",
    "    page_with_vector['contentVector'] = generate_embeddings(page.page_content)\n",
    "    doc_with_vector_list.append(page_with_vector)\n",
    "    doc_id += 1\n",
    "\n",
    "# Output embeddings to docVectors.json file\n",
    "with open(\"./sk_Vectors.json\", \"w\") as f:\n",
    "    json.dump(doc_with_vector_list, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create search index - DO THIS ONLY ONCE !!!\n",
    "Create your search index schema and vector search configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sk-cogsrch-vector-index-2 created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "# Note: You must create Cognitive Search resource and get the endpoint and key in advance\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    # doc id - mandatory field\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True,sortable=True, filterable=True, facetable=True),\n",
    "\n",
    "    # title and titleVector\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"sk-vector-config\"),\n",
    "\n",
    "    # content and contentVector\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"sk-vector-config\"),\n",
    "\n",
    "]\n",
    "\n",
    "#The Hierarchical Navigable Small World (HNSW) graph algorithm is a popular method for approximate nearest neighbour search in high-dimensional spaces.\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"sk-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,                  #maximum number of edges per node in the zero or base layer of the HNSW graph.\n",
    "                \"efConstruction\": 400,   #this parameter affects the index building during the construction phase.Increasing efConstruction will usually improve the quality of the constructed graph, leading to better recall. However, it will also slow down the index building process.\n",
    "                \"efSearch\": 500,         #this parameter affects the search time of the query phase. A higher value of efSearch increases the search time but usually results in better recall. \n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"sk-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=\"sk-cogsrch-vector-index-2\", fields=fields,vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert text and embeddings into vector store - DO THIS ONLY ONCE !!\n",
    "Add texts and metadata from the JSON data to the vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 187 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to the index\n",
    "with open('./sk_Vectors.json', 'r') as file:\n",
    "    documents = json.load(file)\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.8773118\n",
      "Content: Tell us about y our PDF experience.What is Semantic Kernel?\n",
      "Article ‚Ä¢07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8760598\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8751525\n",
      "Content: Additional learning for Semantic Kernel\n",
      "Article ‚Ä¢07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own ‚ÄúEasy Bake Oven.‚Äù W e‚Äôll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      "¬†\n",
      "Kernel syntax examplesStart the tut orial\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search\n",
    "query = \"semantic kernel?\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query),\n",
    "    top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.87037426\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8700597\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8677625\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n"
     ]
    }
   ],
   "source": [
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.83616716\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8347511\n",
      "Content: Additional learning for Semantic Kernel\n",
      "Article ‚Ä¢07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own ‚ÄúEasy Bake Oven.‚Äù W e‚Äôll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      "¬†\n",
      "Kernel syntax examplesStart the tut orial\n",
      "Title: Semantic Kernel\n",
      "Score: 0.8335869\n",
      "Content: Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article ‚Ä¢05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "Ôºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search multi-lingual\n",
    "query = \"Planificador sem√°ntico del kernel y kernel\"\n",
    "\n",
    "search_client = SearchClient(\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Cross-Field Vector Search with a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Semantic Kernel\n",
      "Score: 0.01666666753590107\n",
      "Content: Tell us about y our PDF experience.What is Semantic Kernel?\n",
      "Article ‚Ä¢07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n",
      "Title: Semantic Kernel\n",
      "Score: 0.01666666753590107\n",
      "Content: Supported Semantic Kernel languages\n",
      "Article ‚Ä¢07/18/2023\n",
      "Semantic K ernel plans on providing support to the following languages:\n",
      "While the overall architecture of the kernel is consistent across all languages, we made\n",
      "sure the SDK for each language follows common paradigms and styles in each language\n",
      "to make it feel native and easy to use.\n",
      "Today, not all features are available in all languages. The following tables show which\n",
      "features are available in each language. The üîÑ  symbol indicates that the feature is\n",
      "partially implemented, please see the associated note column for more details. The ‚ùå\n",
      "symbol indicates that the feature is not yet available in that language; if you would like\n",
      "to see a feature implemented in a language, please consider contributing to the project\n",
      "or opening an issue .\n",
      "Services C# Python JavaNotes\n",
      "TextGeneration ‚úÖ‚úÖ‚úÖ Example: T ext-Davinci-003\n",
      "TextEmbeddings ‚úÖ‚úÖ‚úÖ Example: T ext-Embeddings-Ada-002\n",
      "ChatCompletion ‚úÖ‚úÖ‚úÖ Example: GPT4, Chat-GPTÔºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "C#ÔºÇ\n",
      "PythonÔºÇ\n",
      "Java ( available here ) ÔºÇ\n",
      "Available features\n",
      "AI Services\n",
      "Title: Semantic Kernel\n",
      "Score: 0.016393441706895828\n",
      "Content: Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article ‚Ä¢05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "Ôºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n",
      "Title: Semantic Kernel\n",
      "Score: 0.016393441706895828\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n",
      "Title: Semantic Kernel\n",
      "Score: 0.016129031777381897\n",
      "Content: all the existing embedding vectors to find the most similar ones. This is similar to when\n",
      "you make a search query on Bing, and it gives you multiple results that are proximate to\n",
      "your query. Semantic memory is not likely to give you an exact match ‚Äî but it will\n",
      "always give you a set of matches ranked in terms of how similar your query matches\n",
      "other pieces of text.\n",
      "Since a prompt is a text that we give as input to an AI model to generate a desired\n",
      "output or response, we need to consider the length of the input text based on the token\n",
      "limit of the model we choose to use. For example, GPT-4 can handle up to 8,192 tokens\n",
      "per input, while GPT-3 can only handle up to 4,096 tokens. This means that texts that are\n",
      "longer than the token limit of the model will not fit and may be cut off or ignored.\n",
      "It would be nice if we could use an entire 10,000-page operating manual as context for\n",
      "our prompt, but because of the token limit constraint, that is impossible. Therefore,\n",
      "embeddings are useful for breaking down that large text into smaller pieces. W e can do\n",
      "this by summarizing each page into a shorter paragraph and then generating an\n",
      "embedding vector for each summary. An embedding vector is like a compressed\n",
      "representation of the text that preserves its meaning and context. Then we can compare\n",
      "the embedding vectors of our summaries with the embedding vector of our prompt and\n",
      "select the most similar ones. W e can then add those summaries to our input text as\n",
      "context for our prompt. This way, we can use embeddings to help us choose and fit\n",
      "large texts as context within the token limit of the model.Why are embeddings important with LLM AI?\n",
      "Take the next step\n",
      "Learn about embeddings\n",
      "Title: Semantic Kernel\n",
      "Score: 0.016129031777381897\n",
      "Content: Semantic Kernel FAQ's\n",
      "Article ‚Ä¢05/23/2023\n",
      "Both C# and Python are popular coding language and we're actively adding additional\n",
      "languages based on community feedback. Both Java  and Typescript  are on our\n",
      "roadmap and being actively developed in experimental branches.\n",
      "We have sample apps  and plugins you can try out so you can quickly learn the concepts\n",
      "of Semantic K ernel.\n",
      "There are a variety of support options available !\n",
      "Depending upon the model you are trying to access, there may be times when your key\n",
      "may not work because of high demand. Or, because your access to the model is limited\n",
      "by the plan you're currently signed up for ‚Äî so-called \"throttling\". In general, however,\n",
      "your key will work according to the plan agreement with your LLM AI provider.\n",
      "First of all, you'll need to be running locally on your own machine to interact with the\n",
      "Jupyter notebooks. If you've already cleared that hurdle, then all you need to do is to\n",
      "install the Polyglot Extension  which requires .NET 7 to be installed. For complete\n",
      "information on the latest release of P olyglot Extension you can learn more here .Why is the Kernel only in C# and Python?\n",
      "Where are the sample plugins?\n",
      "How do I get help or provide feedback?\n",
      "Is something up with my OpenAI or Azure\n",
      "OpenAI key?\n",
      "Why aren't my Jupyter notebooks coming up in\n",
      "my VSCode or Visual Studio?\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"programming languages supported by semantic kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"titleVector, contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\"] #searching on two fields title and content\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'azure.search.documents._paging.SearchItemPaged'>\n",
      "Title: Semantic Kernel\n",
      "Score: 0.03306011110544205\n",
      "Content: To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.032258063554763794\n",
      "Content: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Score: 0.03067915514111519\n",
      "Content: This article only scratches the surface of what you can do with the kernel. T o learn more\n",
      "about additional features, check out the following articles.\n",
      "Your go al Next st ep\n",
      "Learn what plugins are and what they can do Understand AI plugins\n",
      "Create more advanced pipelines with Semantic K ernel Chaining functions together\n",
      "Automatically creating pipelines with Planner Auto create plans with planner\n",
      "Simulating memory within Semantic K ernel Give you AI memories\n",
      "Under standing plugins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    filter=\"title eq 'Semantic Kernel'\",\n",
    "    select=[\"title\", \"content\",],\n",
    "    top=3\n",
    ")\n",
    "\n",
    "print(type(results))\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Content: {result['content']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Semantic Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Answer: Semantic Kernel.<em> any other operation that you can do in code that is ill-suited for</em> LLMs<em> (e.g., performing calculations).</em> Instead of providing a separate configuration file with semantic descriptions,<em> planner is able to use annotations in the code to understand how the function behaves.</em>\n",
      "Semantic Answer Score: 0.71630859375\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Content: To instantiate planner, all you need to do is pass it a kernel object. Planner will then\n",
      "automatically discover all of the plugins registered in the kernel and use them to create\n",
      "plans. The following code initializes both a kernel and a SequentialPlanner. At the end\n",
      "of this article we'll review the other types of Planners that are available in Semantic\n",
      "Kernel.\n",
      "C#      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) -\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "  [SKFunction, Description( \"Multiply two numbers. When increasing by a  \n",
      "percentage, don't forget to add 1 to the percentage.\" )]\n",
      "  [SKParameter( \"input\", \"The first number to multiply\" )]\n",
      "  [SKParameter( \"number2\" , \"The second number to multiply\" )]\n",
      "  public string Multiply (SKContext context )\n",
      "  {\n",
      "      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) *\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "  [SKFunction, Description( \"Divide two numbers\" )]\n",
      "  [SKParameter( \"input\", \"The first number to divide from\" )]\n",
      "  [SKParameter( \"number2\" , \"The second number to divide by\" )]\n",
      "  public string Divide(SKContext context )\n",
      "  {\n",
      "      return (\n",
      "          Convert.ToDouble(context[ \"input\"], \n",
      "CultureInfo.InvariantCulture) /\n",
      "          Convert.ToDouble(context[ \"number2\" ], \n",
      "CultureInfo.InvariantCulture)\n",
      "      ).ToString(CultureInfo.InvariantCulture);\n",
      "  }\n",
      "}\n",
      "Instantiating planner\n",
      "C#\n",
      "Caption: Semantic Kernel. To instantiate planner, all you need to do is pass it a<em> kernel</em> object. Planner will then automatically discover all of the plugins registered in the kernel and use them to create<em> plans.</em> The following code initializes both a kernel and a SequentialPlanner.\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Content: C#\n",
      "You should get a response like the following. Notice how the response is now more\n",
      "natural sounding.\n",
      "Output\n",
      "You are now becoming familiar with orchestrating both semantic and non-semantic\n",
      "functions. Up until now, however, you've had to manually orchestrate the functions. In\n",
      "the next section, you'll learn how to use planner to orchestrate functions automatically.using Microsoft.SemanticKernel;\n",
      "using Plugins;\n",
      "// ... instantiate your kernel\n",
      "var pluginsDirectory =  \n",
      "Path.Combine(System.IO.Directory.GetCurrentDirectory(), \"plugins\" );\n",
      "// Import the semantic functions\n",
      "kernel.ImportSemanticSkillFromDirectory(pluginsDirectory, \n",
      "\"OrchestratorPlugin\" );\n",
      "kernel.ImportSemanticSkillFromDirectory(pluginsDirectory, \n",
      "\"SummarizeSkill\" );\n",
      "// Import the native functions\n",
      "var mathPlugin = kernel.ImportSkill( new MathPlugin(), \"MathPlugin\" );\n",
      "var orchestratorPlugin = kernel.ImportSkill( new \n",
      "OrchestratorPlugin(kernel), \"OrchestratorPlugin\" );\n",
      "// Make a request that runs the Sqrt function\n",
      "var result1 = await orchestratorPlugin[ \"RouteRequest\" ]\n",
      "    .InvokeAsync( \"What is the square root of 524?\" );\n",
      "Console.WriteLine(result1);\n",
      "// Make a request that runs the Add function\n",
      "var result2 = await orchestratorPlugin[ \"RouteRequest\" ]\n",
      "    .InvokeAsync( \"How many sheep would I have if I started with 3 and  \n",
      "then got 7 more?\" );\n",
      "Console.WriteLine(result2);\n",
      "The square root of 524 is 22.891046284519195.\n",
      "You would have 10 sheep.\n",
      "Take the next step\n",
      "Caption: in the next section, you'll learn how to use<em> planner</em> to orchestrate<em> functions</em> automatically.using microsoft.semantickernel; using<em> plugins;</em> // ... instantiate your<em> kernel</em> var<em> pluginsdirectory</em> =   path.combine(system.io.directory.getcurrentdirectory(), \"plugins\" ); // import the<em> semantic functions</em> ‚Ä¶\n",
      "\n",
      "Title: Semantic Kernel\n",
      "Content: Now that we have planner, we can use it to create a plan for a user's ask and then\n",
      "invoke the plan to get a result. The following code asks our planner to solve a math\n",
      "problem that is difficult for an LLM to solve on its own because it requires multiple steps\n",
      "and it has numbers with decimal points.\n",
      "C#\n",
      "After running this code, you should get the correct answer of 2615.1829 back, but how?\n",
      "Behind the scenes, planner uses an LLM prompt to generate a plan. Y ou can see the\n",
      "prompt that is used by SequentialPlanner by navigating to the skprompt.t xt file  in the\n",
      "Semantic K ernel repository. Y ou can also view the prompt used by the basic planner  in\n",
      "Python.using Microsoft.SemanticKernel;\n",
      "using Plugins;\n",
      "// ... instantiate your kernel\n",
      "// Add the math plugin\n",
      "var mathPlugin = kernel.ImportSkill( new MathPlugin(), \"MathPlugin\" );\n",
      "// Create planner\n",
      "var planner = new SequentialPlanner(kernel);\n",
      "Creating and running a plan\n",
      "C#\n",
      "// Create a plan for the ask\n",
      "var ask = \"If my investment of 2130.23 dollars increased by 23%, how  \n",
      "much would I have after I spent $5 on a latte?\" ;\n",
      "var plan = await planner.CreatePlanAsync(ask);\n",
      "// Execute the plan\n",
      "var result = await plan.InvokeAsync();\n",
      "Console.WriteLine( \"Plan results:\" );\n",
      "Console.WriteLine(result.Result);\n",
      "How does planner work?\n",
      "Caption: y ou can also view the prompt used by the basic<em> planner</em>  in python.using microsoft.semantickernel; using plugins; // ... instantiate your<em> kernel</em> // add the math plugin var mathplugin = kernel.importskill( new mathplugin(), \"mathplugin\" ); // create<em> planner</em> var<em> planner</em> = new<em> sequentialplanner(kernel);</em> creating and running a<em> plan</em> c# // create a ‚Ä¶\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Semantic Hybrid Search\n",
    "query = \"semantic kernel planner and kernel\"\n",
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector=generate_embeddings(query), top_k=3,\n",
    "    vector_fields=\"contentVector\",\n",
    "    select=[\"title\", \"content\"],\n",
    "    query_type=\"semantic\", query_language=\"en-us\", semantic_configuration_name='sk-semantic-config', query_caption=\"extractive\", query_answer=\"extractive\",\n",
    "    top=3\n",
    ")\n",
    "\n",
    "semantic_answers = results.get_answers()\n",
    "for answer in semantic_answers:\n",
    "    if answer.highlights:\n",
    "        print(f\"Semantic Answer: {answer.highlights}\")\n",
    "    else:\n",
    "        print(f\"Semantic Answer: {answer.text}\")\n",
    "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Content: {result['content']}\")\n",
    "\n",
    "    captions = result[\"@search.captions\"]\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\\n\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
